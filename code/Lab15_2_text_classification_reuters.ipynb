{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Lab15_2_text_classification_reuters.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9TnJztDZGw-n"},"source":["# Text classification with an RNN\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lUWearf0Gw-p"},"source":["### 뉴스 분석\n","* 1986년에 로이터에서 공개한 짧은 뉴스 기사와 토픽의 집합인 로이터 데이터셋을 사용\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_2VQo4bajwUU"},"source":["## Setup"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"z682XYsrjkY9","colab":{}},"source":["import tensorflow_datasets as tfds\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HvF-JsSyxUnd","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","from keras.datasets import reuters\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Embedding\n","from keras.preprocessing import sequence\n","from keras.utils import np_utils"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pRmMubr0jrE2"},"source":["## DataSet\n","\n","* keras에서 제공되는 reuters datasets  이용\n","* 46개의 토픽,  각 토픽은 학습 세트에 최소한 10개의 샘플로 구성\n","* 8,982개의 학습 샘플과 2,246개의 테스트 샘플로 구성"]},{"cell_type":"code","metadata":{"id":"PHkOZljJxUng","colab_type":"code","colab":{}},"source":["# num_words=10000, 데이터에서 가장 자주 등장하는 단어 1만 개 로 제한\n","\n","(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n","     "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yHAdwJEhxUni","colab_type":"code","colab":{}},"source":["#data size, data 내용 확인\n","print(\"train data =\", len(train_data))\n","print(\"test data = \", len(test_data))\n","print(\"train_data[0]=\", train_data[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ks7r74EfxUnk","colab_type":"code","colab":{}},"source":["#encoding, decoding \n","word_index = reuters.get_word_index()\n","print(word_index['happy'])\n","\n","indexWord = {}\n","for key, value in word_index.items():\n"," indexWord[value] = key\n","print(indexWord[100])\n","\n","s = \"\"\n","for x in  train_data[0]:\n","    s += indexWord[x] + \" \"\n","print(\"train_data[0]=\",s)            "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_QOM4PNhxUnm","colab_type":"code","colab":{}},"source":["\n","def encode(str):\n","    slist = str.split()\n","    s = []\n","    for w in slist:\n","        s.append(word_index[w])\n","    return(s)    \n","\n","def decode(elist):\n","    s = \"\"\n","    for c in elist:\n","        print(c)\n","        s += indexWord[c] + \" \"\n","    return(s)    \n","\n","s = \"i have a dream\"\n","es = encode(s)\n","print(es)\n","ds = decode(es)\n","print(ds)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GlYWqhTVlUyQ"},"source":["## 학습을 위한 데이터 전처리"]},{"cell_type":"code","metadata":{"id":"CGkv2TiqxUnp","colab_type":"code","colab":{}},"source":["# 데이터를 pad seauence로 변환\n","X_train = sequence.pad_sequences(train_data, maxlen=100)\n","X_test = sequence.pad_sequences(test_data, maxlen=100)\n","# 레이블을 범주형으로 변환\n","y_train = np_utils.to_categorical(train_labels)\n","y_test = np_utils.to_categorical(test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bjUqGVBxGw-t"},"source":["## 모델 생성"]},{"cell_type":"code","metadata":{"id":"VS60V2YnxUnr","colab_type":"code","colab":{}},"source":["#mode 구성\n","model = Sequential([\n","    Embedding(1000, 120),\n","    LSTM(120),\n","    Dense(46, activation='softmax')])\n","    \n","model.compile(loss='categorical_crossentropy', optimizer='adam',\n"," metrics=['accuracy'])    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zIwH3nto596k"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hw86wWS4YgR2","colab":{}},"source":["history = model.fit(X_train, y_train, batch_size=100,  epochs=20, validation_data=(X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Q-h-4tXxUnv","colab_type":"code","colab":{}},"source":["print('\\n 테스트 정확도 : %.4f' % (model.evaluate(X_test, y_test)[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GeG6FMfa-Iui","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","def plot_graphs(history, metric):\n","  plt.plot(history.history[metric])\n","  plt.plot(history.history['val_'+metric], '')\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(metric)\n","  plt.legend([metric, 'val_'+metric])\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"brPMS20W-Jbx","colab_type":"code","colab":{}},"source":["plot_graphs(history, 'accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jo_jXgUl-Sip","colab_type":"code","colab":{}},"source":["plot_graphs(history, 'loss')"],"execution_count":null,"outputs":[]}]}